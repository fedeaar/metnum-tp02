% === INTRO === %

\vspace{1em}
\subsection{Introducción teórica} El método de la potencia con deflación permite aproximar un subconjunto de los autovalores y autovectores asociados a una matriz. Si la misma satisface que todos sus autovalores son no nulos y diferentes en módulo, entonces permite aproximar el conjunto entero. 


\vspace{2em}
\noindent \textsc{Método de la potencia}: el método de la potencia, \textit{Power method} o \textit{Power iteration}, es una técnica iterativa para aproximar el autovector asociado al autovalor en módulo máximo de una matriz cuadrada que satisfaga esta característica ---es decir, tenga un autovalor dominante no nulo---, a partir de la aplicación de sucesivos productos matriciales, descriptos por la siguiente relación de recurrencia:

\begin{equation*}
    b_0\ \text{es un vector aleatorio} : ||b_0|| = 1
\end{equation*}

\begin{equation} \label{potencia}
    b_{k+1} = \frac{\mathbf{A}b_k}{||\mathbf{A}b_k||}
\end{equation}

\vspace{1em}
\noindent donde $|| \cdot ||$ es una norma vectorial.

\vspace{1em}
Se puede demostrar \cite{Burden} que, bajo las condiciones descriptas, si $b_0$ no es ortogonal al autovector asociado al autovalor dominante en módulo de \textbf{A}, $b_k$ convergerá a éste. Lo que es más, se podrá aproximar el autovalor dominante por medio del coeficiente de Rayleigh:

\vspace{1em}
\begin{equation} \label{rayleigh}
    \lambda_{max} = \frac{b_k^t\ \mathbf{A}\ b_k}{b_k^t\ b_k}
\end{equation}


\vspace{3em}
\noindent \textsc{Método de la deflación}: el método de la deflación, por su parte, corresponde a la transformación de la matriz inicial \textbf{A} por una matriz \textbf{B} con autovalores equivalentes, salvo por el autovalor dominante que será anulado. Existen distintos métodos de deflación, entre ellos la deflación de Hotelling y la deflación de Wielandt \cite{Burden}.  

\vspace{1em}
En este trabajo utilizarmos la deflación de Hotelling por su sencillez, a cuestas de un mayor error numérico \cite{Burden}. El mismo consiste en aplicar el método de la potencia para sucesivas matrices que satisfagan la siguiente relación de recurrencia:

\vspace{1em}
\begin{equation*}
    \mathbf{B}_0\ = \mathbf{A}
\end{equation*}

\begin{equation} \label{deflacion}
    \mathbf{B}_{k+1} = \mathbf{B}_{k} - \lambda\ v\ v^t 
\end{equation}

\vspace{1em}
\noindent donde $\lambda$ corresponde al autovalor de módulo máximo estimado por el método de la potencia y $v$ su autovector asociado.

\vspace{1em}
Se puede demostrar \TODO{citar} que $\mathbf{B}_{k+1}$ contiene los mismos autovalores que $\mathbf{B}_{k}$, salvo el máximo que quedará anulado. %Además, si \textbf{A} es simétrica: 

%\vspace{1em}
%\begin{equation*}
%   \mathbf{B}_k\ \xrightarrow[k\ \to\ n]{}\ \mathbf{0}
%\end{equation*}


%\vspace{1em}
%\noindent donde $n$ es la cantidad de columnas o filas de la matriz. Es decir, el proceso de deflación tenderá hacia la matriz nula.\footnote{Una demostración de esta afirmación se puede encontrar en el apéndice \TODO{XXX}.} 

%$\mathbf{B}_k$ es simétrica\footnote{se puede demostrar que $\lambda v v^t$ es simétrica, por lo que $\mathbf{B}_k$ es simétrica por suma de simétricas.}, en consecuencia diagonalizable y satisface que $\mu_{a}(0) \geq k$. Como la matriz nula es la única matriz diagonalizable con $\mu_{a}(0) = n$, entonces debe ser que $\mathbf{B}_n$ es la matriz nula.  




% === IMPLEMENTACION === %

\vspace{2em}
\subsection{Implementación} Procedemos a detallar una posible implementación para ambos métodos, restringiéndonos al caso de autovalores reales. Definimos:

\begin{align*}
    \text{\textit{deflacion}}&:\ \text{\textit{matriz}}_{n \times n}\ \mathbf{A}\ \times\ \text{\textit{nat} q}\ \times\ \text{\textit{nat} k}\ \times\ \text{\textit{real} t}\
    \longrightarrow\ \text{\textit{vector}}_q\ \times\ \text{\textit{matriz}}_{n \times q}
    \\ \\
    \text{\textit{potencia}}&:\ \text{\textit{matriz}}_{n \times n}\ \mathbf{A}\ \times\ \text{\textit{nat} k}\ \times\ \text{\textit{real} t}\ 
    \longrightarrow\ \text{\textit{real}}\ \times\ \text{\textit{vector}}_n
\end{align*}

\vspace{1em}
\noindent donde $n$ es un natural, \textbf{A} tiene al menos $q$ autovalores reales dominantes en módulo, $0 < q \leq n$, $k$ es un número par\footnote{Esta restricción no es necesaria, pero permite realizar una optimización que se explica en la próxima página.} que representa el máximo de iteraciones a realizar y $0 \leq t$ representa la tolerancia mínima a partir de la que se considera la convergencia de una solución. 

\vspace{1em}
\lstinputlisting[language=pseudo, caption={Pseudocódigo para el método de la deflación.}, label=algo_deflacion]{files/src/.code/deflacion.pseudo}

\vspace{1em}
El algoritmo (\ref{algo_deflacion}.) retornará un vector con los primeros $q$ autovalores en módulo máximos de \textbf{A}, ordenados descendientemente, y una matriz cuyas columnas corresponden, respectivamente, a los autovectores normalizados asociados a estos autovalores. 

\vspace{1em}
Es intersante notar que la $k$-ésima matriz sobre la que se aplicará el método de la potencia ---\textbf{B}$_k$--- tendrá, por definición, un autovalor cero con multiplicidad algebráica mayor o igual a $k$. En el caso en que la matriz inicial sea simétrica, \textbf{B}$_k$ será simétrica\footnote{Por suma de simétricas. Notar que $v v^t$ siempre resulta en una matriz de este tipo.} y, en consecuencia, diagonalizable. Se puede demostrar que la única matriz diagonalizable con multiplicidad algebráica $\mu_{a}(0) = n$ es la matriz nula, por lo que el método de la deflación de Hotelling tenderá hacia ella. Esto nos permite inferir que el error númerico será mayor para los autovalores más chicos de la matriz.  


\vspace{2em}
\noindent Por su parte, el algoritmo (\ref{algo_potencia}.) retornará el autovalor de \textbf{A} máximo en módulo y su autovector asociado:

\vspace{1em}
\lstinputlisting[language=pseudo, caption={Pseudocódigo para el método de la potencia.}, label=algo_potencia]{files/src/.code/potencia.pseudo}

\vspace{1em}
\TODO{explicar aspectos relevantes.}





% === EVALUACION === %

\vspace{2em}
\subsection{Evaluación cuantitativa} Procederemos a evaluar nuestra implementación del método de la potencia con deflación en C++ acorde a los algoritmos propuestos.

\vspace{1em}
\textsc{Error relativo} Medimos el error $|\mathbf{A} \mathbf{V} - \mathbf{V} \mathbf{\Lambda}|_1$ en función de la cantidad de iteraciones $k$ para 300 instancias de matrices $\in \mathbb{R}^{25 \times 25}$ generadas aleatoriamente, donde \textbf{V} y $\mathbf{\Lambda}$ representan ---respectivamente--- las matrices aproximadas de autovectores y autovalores de \textbf{A}, tal que $\mathbf{A}\mathbf{V}_i \approx \mathbf{\Lambda}_{ii} \mathbf{V}_i$ $\forall i:\ 1\ ...\ n$.  En total, obtuvimos \TODO{XXX} mediciones\footnote{El script asociado se puede encontrar en $./experimentos/error\_potencia.py$}.  


\vspace{1em}
\noindent \textsc{Metodología}. Se calculó  $\mathbf{\Lambda}, \mathbf{V} = Deflacion(\mathbf{A},\ 25,\ k,\ 0)$ y se midió el error relativo para cada una de las matrices sobre cada valor de $k$ en en el intervalo $(0, 1e6)$, de a saltos de $1e3$.

\vspace{1em}
\noindent Cada caso se generó a través de uno de los siguientes tres procedimientos\footnote{Se utilizó un valor semilla para facilitar la reproductibilidad.}:

\vspace{1em}
\begin{enumerate}
    \item \textit{Matrices Diagonales}: Se generaron cien matrices diagonales \textbf{D} con veinticinco autovalores en el rango $[-1e6,\ 1e6]$ tal que ningun autovalor compartiera valor absoluto en módulo con ningún otro. Los mismos se generaron con el rng \textit{PCG64} de numpy para evitar distribuciones particulares que pudieran influir en la variabilidad de los autovalores.

    \item \textit{Matrices Diagonalizables}: Se generaron cien matrices diagonalizables $\mathbf{A} = \mathbf{Q}\mathbf{D}\mathbf{Q}^t$ donde cada matriz $\mathbf{D}$ se generó a partir de la metodología (1.) y $\mathbf{Q} = \mathbf{I} - 2uu^t$ se generó a partir de un vector aleatorio $u$ ---con el algoritmo random.rand() de numpy--- tal que $||u||_2 = 1$.

    \item \textit{Matrices Simétricas Definidas Positivas}: Se generaron cien matrices simétricas definidas positivas de enteros. Para cada caso se generó una matriz aleatoria \textbf{B} con el algoritmo \textit{random.randint()} de numpy y se procedió a definir la matriz $\mathbf{A} = \mathbf{B} \mathbf{B}^t$. 

\end{enumerate}


\vspace{1em}
\noindent \textsc{Resultados}. \TODO{experimento}
